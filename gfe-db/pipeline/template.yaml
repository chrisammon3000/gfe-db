AWSTemplateFormatVersion: "2010-09-09"
Transform: AWS::Serverless-2016-10-31
Description: Deploys IAM, ECR repositories, AWS Batch Jobs and a State Machine for the gfe-db update pipeline

Parameters:
  Stage:
    Type: String
    Description: Stage of production
  AppName:
    Type: String
    Description: Application name
  ServiceName:
    Type: String
    Description: Service name
  GithubRepositoryOwner:
    Type: String
  GithubRepositoryName:
    Type: String
  GitHubPersonalAccessToken:
    Type: String
    NoEcho: true
  ConfigS3Path:
    Type: String
    Description: S3 path to config file
  CheckSourceUpdateFunctionName:
    Type: String
  CheckSourceUpdateFunctionMemorySize:
    Type: Number
    MinValue: 128
    MaxValue: 512
  CheckSourceUpdateFunctionTimeout:
    Type: Number
  CheckSourceUpdateFunctionSchedule:
    Type: String
  GetExecutionStateFunctionTimeout:
    Type: Number
  GetExecutionStateFunctionMemorySize:
    Type: Number
  ValidateBuildOutputFunctionName:
    Type: String
  ValidateBuildOutputFunctionMemorySize:
    Type: Number
  ValidateBuildOutputFunctionTimeout:
    Type: Number
  InvokeLoadScriptFunctionName:
    Type: String
  InvokeUpdatePipelineFunctionName:
    Type: String
  ECRBaseUri:
    Type: String
  BuildServiceRepositoryName:
    Type: String

Resources:

  GitHubPersonalAccessTokenSecret:
    Type: AWS::SecretsManager::Secret
    Properties:
      Name: !Sub "/${AppName}/${Stage}/${AWS::Region}/GitHubPersonalAccessToken"
      Description: GitHub Personal Access Token for repository access
      SecretString: !Ref GitHubPersonalAccessToken
      Tags:
        - Key: Stage
          Value: !Ref Stage
        - Key: AppName 
          Value: !Ref AppName
  
  GitHubSourceRepositoryParameter:
    Type: AWS::SSM::Parameter
    Properties:
      Name: !Sub "/${AppName}/${Stage}/${AWS::Region}/GithubSourceRepository"
      Type: String
      Description: GitHub Personal Access Token for repository access
      Value: !Sub '{"owner":"${GithubRepositoryOwner}", "name":"${GithubRepositoryName}"}'

  # Create a lambda layer
  GfeDbModelsLayer:
    Type: AWS::Serverless::LayerVersion
    Properties:
      LayerName: !Sub '${Stage}-gfe-db-models'
      Description: !Sub '${AppName} models for validationa and processing data'
      ContentUri: lambda_layers/gfe_db_models
      RetentionPolicy: delete
      CompatibleRuntimes:
        - python3.10
    Metadata:
      BuildMethod: python3.10
      BuildArchitectures: arm64

  # TODO change name to GfeDbExecutionStateTable
  ExecutionStateTable:
    Type: AWS::DynamoDB::Table
    Properties:
      AttributeDefinitions:
        - AttributeName: 'commit__sha'
          AttributeType: S
        - AttributeName: 'execution__version'
          AttributeType: N
      KeySchema:
        - AttributeName: 'commit__sha'
          KeyType: HASH
        - AttributeName: 'execution__version'
          KeyType: RANGE
      BillingMode: PAY_PER_REQUEST
      # ProvisionedThroughput:
      #   ReadCapacityUnits: 2
      #   WriteCapacityUnits: 2

  ExecutionStateTableNameParameter:
    Type: AWS::SSM::Parameter
    Properties:
      Name: !Sub '/${AppName}/${Stage}/${AWS::Region}/ExecutionStateTableName'
      Type: String
      Value: !Ref ExecutionStateTable

  ExecutionStateTableFieldsParameter:
    Type: AWS::SSM::Parameter
    Properties:
      Type: String
      Name: !Sub '/${AppName}/${Stage}/${AWS::Region}/ExecutionStateTableFields'
      Description: !Sub 'Selected fields for ${Stage}-${AppName} execution state table'
      Tier: Standard
      Value: !Sub |
        [
            "commit.sha",
            "execution.version",
            "commit.date_utc",
            "commit.html_url",
            "commit.message",
            "execution.date_utc",
            "execution.status",
            "execution.input_parameters.align",
            "execution.input_parameters.kir",
            "execution.input_parameters.limit",
            "execution.input_parameters.mem_profile",
            "repository.name",
            "repository.owner",
            "repository.url",
            "created_utc",
            "updated_utc"
        ]

  BuildServerSG:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupName: !Sub '${Stage}-${AppName}-build-server-sg'
      GroupDescription: !Sub 'Security group for the ${Stage}-${AppName} build server'
      VpcId: !Sub '{{resolve:ssm:/${AppName}/${Stage}/${AWS::Region}/VpcID}}'
      SecurityGroupIngress: # Uncomment to allow SSH access to build instance
        - CidrIp: 0.0.0.0/0
          FromPort: 22
          IpProtocol: tcp
          ToPort: 22
      Tags:
        - Key: Name
          Value: !Sub '${Stage}-${AppName}-build-server-sg'

  BatchServiceRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Effect: Allow
            Principal:
              Service: batch.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSBatchServiceRole
        
  BatchWorkerInstanceProfile:
    Type: AWS::IAM::InstanceProfile
    Properties:
      Roles:
        - !Ref BatchWorkerInstanceRole

  BatchWorkerInstanceRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: "2008-10-17"
        Statement:
          - Sid: ""
            Effect: Allow
            Principal:
              Service: ec2.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AmazonEC2ContainerServiceforEC2Role
        - arn:aws:iam::aws:policy/AmazonS3FullAccess
        - arn:aws:iam::aws:policy/CloudWatchAgentServerPolicy
      Policies:
        - PolicyName: !Sub '${Stage}-${AppName}-ECS-CloudWatchLogs'
          PolicyDocument: 
            Version: "2012-10-17"
            Statement:
              - Action:
                  - "logs:CreateLogGroup"
                  - "logs:CreateLogStream"
                  - "logs:PutLogEvents"
                  - "logs:DescribeLogStreams"
                Effect: "Allow"
                Resource: "arn:aws:logs:*:*:*"
        - PolicyName: !Sub '${Stage}-${AppName}-BuildServiceS3ReadWritePolicy'
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: "Allow"
                Action: 
                  - "s3:GetObject"
                  - "s3:ListBucket"
                  - "s3:GetBucketLocation"
                  - "s3:GetObjectVersion"
                  - "s3:GetLifecycleConfiguration"
                  - "s3:PutObject"
                  - "s3:PutObjectAcl"
                  - "s3:PutLifecycleConfiguration"
                  - "s3:DeleteObject"
                Resource:
                  - !Sub '{{resolve:ssm:/${AppName}/${Stage}/${AWS::Region}/DataBucketArn}}'
                  - !Sub '{{resolve:ssm:/${AppName}/${Stage}/${AWS::Region}/DataBucketArn}}/*'
        - PolicyName: !Sub '${Stage}-${AppName}-SecretsPolicy'
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: "Allow"
                Action: 
                  - "ssm:GetParameters"
                  - "ssm:GetParameter"
                  - "secretsmanager:GetResourcePolicy"
                  - "secretsmanager:GetSecretValue"
                  - "secretsmanager:DescribeSecret"
                  - "secretsmanager:ListSecretVersionIds"
                  - "secretsmanager:ListSecrets"
                Resource: 
                  - "*"
        - PolicyName: !Sub '${Stage}-${AppName}-SQSPolicy'
          PolicyDocument:
            Version: '2012-10-17' 
            Statement:
              - Effect: Allow
                Action:
                  - "sqs:GetQueueAttributes"
                  - "sqs:SendMessageBatch"
                  - "sqs:SendMessage"
                  - "sqs:ReceiveMessage"
                  - "sqs:DeleteMessage"
                Resource:
                  - !GetAtt FailedAllelesQueue.Arn

  BuildJobDefinition:
    Type: AWS::Batch::JobDefinition
    Properties:
      Type: container
      JobDefinitionName: !Sub '${Stage}-${AppName}-BuildJobDefinition'
      ContainerProperties:
        Image: !Sub '${ECRBaseUri}/${BuildServiceRepositoryName}:latest'
        Vcpus: 8
        # TODO: Memory param is deprecated, move to ResourceRequirements
        Memory: 8000 # Keep this around half the available RAM to avoid getting stuck in RUNNABLE status
        # ResourceRequirements:
        #   Type: MEMORY
        #   Value: 8000
        Command:
          - bash
          - run.sh
        Environment:
          - Name: GFE_BUCKET
            Value: !Sub '{{resolve:ssm:/${AppName}/${Stage}/${AWS::Region}/DataBucketName}}'
          - Name: FAILED_ALLELES_QUEUE
            Value: !Ref FailedAllelesQueue
          - Name: AWS_REGION
            Value: !Ref AWS::Region
      RetryStrategy:
        Attempts: 1

  BuildJobQueue:
    Type: AWS::Batch::JobQueue
    Properties:
      JobQueueName: !Sub '${Stage}-${AppName}-BuildJobQueue'
      Priority: 1
      ComputeEnvironmentOrder:
        - Order: 1
          ComputeEnvironment: !Ref BuildComputeEnvironment

  # SSM Parameter for the BuildJobQueue ARN
  BuildJobQueueArn:
    Type: AWS::SSM::Parameter
    Properties:
      Name: !Sub '/${AppName}/${Stage}/${AWS::Region}/BuildJobQueueArn'
      Type: String
      Value: !GetAtt BuildJobQueue.JobQueueArn

  BuildComputeEnvironment:
    Type: AWS::Batch::ComputeEnvironment
    Properties:
      Type: MANAGED
      ComputeResources:
        Type: EC2
        # # Testing only, comment before prouction deployment
        # Ec2KeyPair: !Ref EC2KeyPairName
        # #
        MinvCpus: 0
        DesiredvCpus: 0
        MaxvCpus: 32
        InstanceTypes:
          - c5d.2xlarge
        Subnets:
          - !Sub '{{resolve:ssm:/${AppName}/${Stage}/${AWS::Region}/PublicSubnetID}}'
        SecurityGroupIds:
          - !Ref BuildServerSG
        InstanceRole: !Ref BatchWorkerInstanceProfile
        LaunchTemplate:
          LaunchTemplateId: !Ref BuildLaunchTemplate
        Tags: { "Name": "gfe-db-build-worker" }
      ServiceRole: !GetAtt BatchServiceRole.Arn

  BuildLaunchTemplate:
    Type: AWS::EC2::LaunchTemplate
    Properties:
      LaunchTemplateData:
        DisableApiTermination: false
        InstanceInitiatedShutdownBehavior: stop
        ImageId: '{{resolve:ssm:/aws/service/ecs/optimized-ami/amazon-linux-2/recommended/image_id}}'
        InstanceType: c5d.xlarge
        IamInstanceProfile:
          Name: !Ref BatchWorkerInstanceProfile
        Monitoring:
          Enabled: true
        SecurityGroupIds:
          - !Ref BuildServerSG
        UserData:
          Fn::Base64: |
            MIME-Version: 1.0
            Content-Type: multipart/mixed; boundary="==MYBOUNDARY=="

            --==MYBOUNDARY==
            Content-Type: text/x-shellscript; charset="us-ascii"

            #!/bin/bash -x
            IDX=1
            for DEV in /dev/disk/by-id/nvme-Amazon_EC2_NVMe_Instance_Storage_*-ns-1; do
              mkfs.xfs ${DEV}
              mkdir -p /local${IDX}
              echo ${DEV} /local${IDX} xfs defaults,noatime 1 2 >> /etc/fstab
              IDX=$((${IDX} + 1))
            done
            mount -a
            sudo yum update -y
            sudo yum install amazon-cloudwatch-agent -y

            --==MYBOUNDARY==
      TagSpecifications:
        - ResourceType: launch-template
          Tags: 
            - Key: Name
              Value: 'gfe-db-build-worker'

  BatchTaskExecutionRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: "2008-10-17"
        Statement:
          - Sid: ""
            Effect: Allow
            Principal:
              Service: ecs-tasks.amazonaws.com
            Action: sts:AssumeRole
      Policies:
        - PolicyName: !Sub '${Stage}-${AppName}-ecsTaskExecutionRolePolicy'
          PolicyDocument: 
            Version: "2012-10-17"
            Statement:
              - Effect: Allow
                Action:
                  - "ecr:GetAuthorizationToken"
                  - "ecr:BatchCheckLayerAvailability"
                  - "ecr:GetDownloadUrlForLayer"
                  - "ecr:BatchGetImage"
                  - "logs:CreateLogStream"
                  - "logs:PutLogEvents"
                Resource: "*"
        - PolicyName: !Sub '${Stage}-${AppName}-BatchTaskExecutionPolicy'
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: "Allow"
                Action: 
                  - "ssm:GetParameters"
                  - "secretsmanager:GetResourcePolicy"
                  - "secretsmanager:GetSecretValue"
                  - "secretsmanager:DescribeSecret"
                  - "secretsmanager:ListSecretVersionIds"
                  - "secretsmanager:ListSecrets"
                Resource: 
                  - "*"
                  
  BuildServiceRepository:
    Type: AWS::ECR::Repository
    Properties:
      RepositoryName: !Ref BuildServiceRepositoryName
      RepositoryPolicyText:
        Version: "2012-10-17"
        Statement:
          - Sid: "AllowPushPull"
            Effect: "Allow"
            Principal:
              AWS:
                - !Sub 'arn:aws:iam::${AWS::AccountId}:role/${BatchWorkerInstanceRole}'
            Action:
              - "ecr:GetDownloadUrlForLayer"
              - "ecr:BatchGetImage"
              - "ecr:BatchCheckLayerAvailability"
              - "ecr:PutImage"
              - "ecr:InitiateLayerUpload"
              - "ecr:UploadLayerPart"
              - "ecr:CompleteLayerUpload"

  BuildServiceRepositoryNameParameter:
    Type: AWS::SSM::Parameter
    Properties:
      Type: String
      Name: !Sub '/${AppName}/${Stage}/${AWS::Region}/BuildServiceRepositoryName'
      Description: !Sub "Name of ${AppName} build service repository"
      Value: !Ref BuildServiceRepositoryName

  GfeDbProcessingQueue:
    Type: AWS::SQS::Queue
    Properties:
      VisibilityTimeout: 300
      MessageRetentionPeriod: 43200
      ReceiveMessageWaitTimeSeconds: 20
      RedrivePolicy:
        deadLetterTargetArn: !GetAtt GfeDbProcessingDeadLetterQueue.Arn
        maxReceiveCount: 3

  GfeDbProcessingDeadLetterQueue:
    Type: AWS::SQS::Queue
    Properties:
      VisibilityTimeout: 43200
      MessageRetentionPeriod: 1209600
      ReceiveMessageWaitTimeSeconds: 10

  GfeDbProcessingQueueUrlParameter:
    Type: AWS::SSM::Parameter
    Properties:
      Type: String
      Name: !Sub '/${AppName}/${Stage}/${AWS::Region}/GfeDbProcessingQueueUrl'
      Description: "URL of gfe-db processing queue"
      Value: !GetAtt GfeDbProcessingQueue.QueueUrl

  CheckSourceUpdateFunction:
    Type: AWS::Serverless::Function
    Properties:
      FunctionName: !Ref CheckSourceUpdateFunctionName
      Description: !Sub '${AppName} update pipeline trigger: checks for new IMGT/HLA releases and starts the loading process'
      CodeUri: functions/check_source_update/
      Handler: app.lambda_handler
      Runtime: python3.9
      Layers:
        - !Ref GfeDbModelsLayer
      MemorySize: !Ref CheckSourceUpdateFunctionMemorySize
      Timeout: !Ref CheckSourceUpdateFunctionTimeout
      Architectures:
        - x86_64
      Environment:
        Variables:
          APP_NAME: !Ref AppName
          STAGE: !Ref Stage
          PIPELINE_SOURCE_CONFIG_S3_PATH: !Sub '${ConfigS3Path}/${ServiceName}/source-config.json'
      Events:
        Trigger:
          Type: Schedule
          Properties:
            Schedule: !Ref CheckSourceUpdateFunctionSchedule
      Policies:
        - AWSLambdaBasicExecutionRole
        - Version: "2012-10-17"
          Statement:
            - Sid: "AllowSecretsManagerAccess"
              Effect: "Allow"
              Action:
                - "secretsmanager:GetSecretValue"
              Resource: !Ref GitHubPersonalAccessTokenSecret
        - Version: "2012-10-17"
          Statement:
            - Sid: "AllowSSMParameterStoreAccess"
              Effect: "Allow"
              Action:
                - "ssm:GetParameters"
                - "ssm:GetParameter"
              Resource: "*"
        - Version: "2012-10-17"
          Statement:
            - Sid: "AllowDynamoDBReadAccess"
              Effect: "Allow"
              Action:
                - "dynamodb:Scan"
                - "dynamodb:BatchWriteItem"
              Resource: !GetAtt ExecutionStateTable.Arn 
        - Version: "2012-10-17"
          Statement:
            - Sid: "AllowSQSAccess"
              Effect: "Allow"
              Action:
                - "sqs:SendMessage"
                - "sqs:GetQueueUrl"
                - "sqs:GetQueueAttributes"
                - "sqs:SendMessageBatch"
              Resource: "*" # TODO: restrict to the queue
        - Version: "2012-10-17"
          Statement:
            - Sid: "AllowS3Access"
              Effect: "Allow"
              Action: 
                - "s3:GetObject"
                - "s3:ListBucket"
                - "s3:GetBucketLocation"
                - "s3:GetObjectVersion"
              Resource:
                - !Sub '{{resolve:ssm:/${AppName}/${Stage}/${AWS::Region}/DataBucketArn}}'
                - !Sub '{{resolve:ssm:/${AppName}/${Stage}/${AWS::Region}/DataBucketArn}}/*'

  GetExecutionStateFunction:
    Type: AWS::Serverless::Function
    Properties:
      Description: !Sub '${AppName} execution input validation and state retrieval'
      CodeUri: functions/get_execution_state/
      Handler: app.lambda_handler
      Runtime: python3.10
      Layers:
        - !Ref GfeDbModelsLayer
      MemorySize: !Ref GetExecutionStateFunctionMemorySize
      Timeout: !Ref GetExecutionStateFunctionTimeout
      Architectures:
        - x86_64
      Environment:
        Variables:
          APP_NAME: !Ref AppName
          STAGE: !Ref Stage
      Policies:
        - AWSLambdaBasicExecutionRole
        - Version: "2012-10-17"
          Statement:
            - Sid: "AllowSSMParameterStoreAccess"
              Effect: "Allow"
              Action:
                - "ssm:GetParameters"
                - "ssm:GetParameter"
              # TODO test correct ARN path for app specific parameters
              # arn:aws:ssm:us-east-2:123456789012:parameter/${AppName}/${Stage}/${AWS::Region}/*
              Resource: !Sub 'arn:aws:ssm:${AWS::Region}:${AWS::AccountId}:parameter/${AppName}/${Stage}/${AWS::Region}/*'
        - Version: "2012-10-17"
          Statement:
            - Sid: "AllowDynamoDBReadAccess"
              Effect: "Allow"
              Action:
                - "dynamodb:ReadItem"
              Resource: !GetAtt ExecutionStateTable.Arn

  # # TODO redeploy
  # CheckSourceUpdateFunctionAlarm:
  #   Type: AWS::CloudWatch::Alarm
  #   Properties:
  #     AlarmDescription: !Sub 'Alarm for ${CheckSourceUpdateFunction} function errors'
  #     ActionsEnabled: true
  #     AlarmActions:
  #       - !Sub '{{resolve:ssm:/${AppName}/${Stage}/${AWS::Region}/DataPipelineErrorsTopicArn}}'
  #     MetricName: Errors
  #     Namespace: AWS/Lambda
  #     Statistic: Sum
  #     Period: 86400
  #     EvaluationPeriods: 1
  #     Threshold: 1
  #     ComparisonOperator: GreaterThanOrEqualToThreshold
  #     Dimensions:
  #       - Name: FunctionName
  #         Value: !Ref CheckSourceUpdateFunctionName

  InvokeUpdatePipelineFunction:
    Type: AWS::Serverless::Function
    Properties:
      FunctionName: !Ref InvokeUpdatePipelineFunctionName
      Description: !Sub "Invoke the build and load processing pipeline for ${AppName}"
      CodeUri: functions/invoke_update_pipeline/
      Handler: app.lambda_handler
      Runtime: python3.9
      MemorySize: 128
      Timeout: 60
      Architectures:
        - x86_64
      Environment:
        Variables:
          NEO4J_DATABASE_INSTANCE_ID_SSM_PARAM: !Sub '/${AppName}/${Stage}/${AWS::Region}/Neo4jDatabaseInstanceId'
          UDPATE_PIPELINE_STATE_MACHINE_ARN_SSM_PARAM: !Sub '/${AppName}/${Stage}/${AWS::Region}/UpdatePipelineStateMachineArn'
          GFE_DB_PROCESSING_QUEUE_URL_SSM_PARAM: !Sub '/${AppName}/${Stage}/${AWS::Region}/GfeDbProcessingQueueUrl'
      Policies:
        - AWSLambdaBasicExecutionRole
        - Version: "2012-10-17"
          Statement:
            - Effect: "Allow"
              Action: 
                - "ssm:GetParameters"
                - "ssm:GetParameter"
              Resource: 
                - "*"
            - Effect: "Allow"
              Action: 
                - "ec2:DescribeInstanceStatus"
              Resource: "*" # Has to be for all resources since Instance ID is not available when this stack is deployed
            - Effect: "Allow"
              Action: 
                - "states:StartExecution"
              Resource: 
                - !GetAtt UpdatePipelineStateMachine.Arn
      Events:
        GfeDbProcessingQueueTrigger:
          Type: SQS
          Properties:
            Queue: !GetAtt GfeDbProcessingQueue.Arn
            BatchSize: 10

  UpdatePipelineStateMachine:
    Type: AWS::Serverless::StateMachine
    Properties:
      DefinitionUri: statemachines/pipeline.asl.json
      DefinitionSubstitutions:
        ExecutionStateTable: !Ref ExecutionStateTable
        DataBucketName: !Sub '{{resolve:ssm:/${AppName}/${Stage}/${AWS::Region}/DataBucketName}}'
        ValidateBuildOutputFunctionArn: !GetAtt ValidateBuildOutputFunction.Arn
        GfeDbExecutionResultTopicArn: !GetAtt GfeDbExecutionResultTopic.TopicArn
        BuildJobDefinition: !Ref BuildJobDefinition
        BuildJobName: !Sub '${Stage}-${AppName}-build-job'
        BuildJobQueue: !Ref BuildJobQueue
        InvokeLoadScriptFunctionArn: !GetAtt InvokeLoadScriptFunction.Arn
        LoadReleaseActivityArn: !Ref LoadReleaseActivity
      Policies:
        - LambdaInvokePolicy:
            FunctionName: GfeDbBuildJobMockFunction
        - LambdaInvokePolicy:
            FunctionName: GfeDbLoadMockFunction
        - LambdaInvokePolicy:
            FunctionName: !Ref ValidateBuildOutputFunction
        - S3ReadPolicy:
            BucketName: !Sub '{{resolve:ssm:/${AppName}/${Stage}/${AWS::Region}/DataBucketName}}'
        - LambdaInvokePolicy:
            FunctionName: !Ref InvokeLoadScriptFunction
        - DynamoDBReadPolicy:
            TableName: !Ref ExecutionStateTable
        - DynamoDBWritePolicy:
            TableName: !Ref ExecutionStateTable
        - SNSPublishMessagePolicy:
            TopicName: !GetAtt GfeDbExecutionResultTopic.TopicName 
        - Version: "2012-10-17"
          Statement:
            - Effect: "Allow"
              Action:
                - "logs:CreateLogDelivery"
                - "logs:GetLogDelivery"
                - "logs:UpdateLogDelivery"
                - "logs:DeleteLogDelivery"
                - "logs:ListLogDeliveries"
                - "logs:PutResourcePolicy"
                - "logs:DescribeResourcePolicies"
                - "logs:DescribeLogGroups"
              Resource: 
                - "*"
        - Version: "2012-10-17"
          Statement:
            - Effect: "Allow"
              Action: 
                - "batch:SubmitJob"
                - "batch:DescribeJobs"
                - "batch:TerminateJob"
              Resource: "*"
            - Effect: "Allow"
              Action: 
                - "events:PutTargets"
                - "events:PutRule"
                - "events:DescribeRule"
              Resource: 
                - !Sub 'arn:aws:events:${AWS::Region}:${AWS::AccountId}:rule/StepFunctionsGetEventsForBatchJobsRule'
      Logging:
        Destinations: 
          - CloudWatchLogsLogGroup: 
              LogGroupArn: !GetAtt UpdatePipelineLogGroup.Arn
        IncludeExecutionData: true
        Level: ALL

  # # TODO Retain the original statemachine until the new one is working
  # UpdatePipelineStateMachine:
  #   Type: AWS::Serverless::StateMachine
  #   Properties:
  #     DefinitionUri: statemachines/pipeline.asl.json
  #     DefinitionSubstitutions:
  #       AppName: !Ref AppName
  #       BuildJobDefinition: !Ref BuildJobDefinition
  #       BuildJobName: !Sub '${Stage}-${AppName}-build-job'
  #       BuildJobQueue: !Ref BuildJobQueue
  #       InvokeLoadScriptFunctionArn: !GetAtt InvokeLoadScriptFunction.Arn
  #       LoadReleaseActivityArn: !Ref LoadReleaseActivity
  #     Policies:
  #       - LambdaInvokePolicy:
  #           FunctionName: !Ref InvokeLoadScriptFunction
  #       - Version: "2012-10-17"
  #         Statement:
  #           - Effect: "Allow"
  #             Action:
  #               - "logs:CreateLogDelivery"
  #               - "logs:GetLogDelivery"
  #               - "logs:UpdateLogDelivery"
  #               - "logs:DeleteLogDelivery"
  #               - "logs:ListLogDeliveries"
  #               - "logs:PutResourcePolicy"
  #               - "logs:DescribeResourcePolicies"
  #               - "logs:DescribeLogGroups"
  #             Resource: 
  #               - "*"
  #       - Version: "2012-10-17"
  #         Statement:
  #           - Effect: "Allow"
  #             Action: 
  #               - "batch:SubmitJob"
  #               - "batch:DescribeJobs"
  #               - "batch:TerminateJob"
  #             Resource: "*"
  #           - Effect: "Allow"
  #             Action: 
  #               - "events:PutTargets"
  #               - "events:PutRule"
  #               - "events:DescribeRule"
  #             Resource: 
  #               - !Sub 'arn:aws:events:${AWS::Region}:${AWS::AccountId}:rule/StepFunctionsGetEventsForBatchJobsRule'
  #     Logging:
  #       Destinations: 
  #         - CloudWatchLogsLogGroup: 
  #             LogGroupArn: !GetAtt UpdatePipelineLogGroup.Arn
  #       IncludeExecutionData: true
  #       Level: ALL

  ValidateBuildOutputFunction:
    Type: AWS::Serverless::Function
    Properties:
      FunctionName: !Ref ValidateBuildOutputFunctionName
      Description: !Sub "Invoke server-side loading on Neo4j for ${AppName}"
      CodeUri: functions/validate_build_output/
      Handler: app.lambda_handler
      Runtime: python3.10
      MemorySize: !Ref ValidateBuildOutputFunctionMemorySize
      Timeout: !Ref ValidateBuildOutputFunctionTimeout
      Architectures:
        - x86_64
      Environment:
        Variables:
          APP_NAME: !Ref AppName
          STAGE: !Ref Stage
      Policies:
        - AWSLambdaBasicExecutionRole
        - Version: "2012-10-17"
          Statement:
            - Effect: "Allow"
              Action: 
                - "ssm:GetParameters"
                - "ssm:GetParameter"
              Resource: 
                - "*"
            - Effect: "Allow"
              Action: 
                - "s3:GetObject"
              Resource: 
                - !Sub "arn:aws:s3:::{{resolve:ssm:/${AppName}/${Stage}/${AWS::Region}/DataBucketName}}/*"

  InvokeLoadScriptFunction:
    Type: AWS::Serverless::Function
    Properties:
      FunctionName: !Ref InvokeLoadScriptFunctionName
      Description: !Sub "Invoke server-side loading on Neo4j for ${AppName}"
      CodeUri: functions/invoke_load_script/
      Handler: app.lambda_handler
      Runtime: python3.9
      MemorySize: 256
      Timeout: 60
      Architectures:
        - x86_64
      Environment:
        Variables:
          NEO4J_LOAD_QUERY_DOCUMENT_NAME_SSM_PARAM: !Sub '/${AppName}/${Stage}/${AWS::Region}/Neo4jLoadQueryDocumentName'
          NEO4J_DATABASE_INSTANCE_ID_SSM_PARAM: !Sub '/${AppName}/${Stage}/${AWS::Region}/Neo4jDatabaseInstanceId'
          LOAD_RELEASE_ACTIVITY_ARN_SSM_PARAM: !Sub '/${AppName}/${Stage}/${AWS::Region}/LoadReleaseActivityArn'
          APP_NAME: !Ref AppName
      Policies:
        - AWSLambdaBasicExecutionRole
        - Version: "2012-10-17"
          Statement:
            - Effect: "Allow"
              Action: 
                - "ssm:SendCommand"
                - "ssm:GetDocument"
              Resource:
                - !Sub 'arn:${AWS::Partition}:ssm:${AWS::Region}:${AWS::AccountId}:document/${Neo4jLoadQueryDocument}'
                - !Sub 'arn:${AWS::Partition}:ec2:${AWS::Region}:${AWS::AccountId}:instance/*'
            - Effect: "Allow"
              Action: 
                - "ssm:GetParameters"
                - "ssm:GetParameter"
              Resource: 
                - "*"

  InvokeLoadScriptFunctionAlarm:
    Type: AWS::CloudWatch::Alarm
    Properties:
      AlarmDescription: !Sub 'Alarm for ${InvokeLoadScriptFunction} function errors'
      ActionsEnabled: true
      AlarmActions:
        - !Sub '{{resolve:ssm:/${AppName}/${Stage}/${AWS::Region}/DataPipelineErrorsTopicArn}}'
      MetricName: Errors
      Namespace: AWS/Lambda
      Statistic: Sum
      Period: 86400
      EvaluationPeriods: 1
      Threshold: 1
      ComparisonOperator: GreaterThanOrEqualToThreshold
      Dimensions:
        - Name: FunctionName
          Value: !Ref InvokeLoadScriptFunctionName

  GfeDbExecutionResultTopic:
    Type: AWS::SNS::Topic

  GfeDbExecutionResultTopicArnParameter:
    Type: AWS::SSM::Parameter
    Properties:
      Type: String
      Name: !Sub '/${AppName}/${Stage}/${AWS::Region}/GfeDbExecutionResultTopicArn'
      Description: !Sub 'ARN for ${AppName} Data Pipeline Errors SNS topic'
      Value: !Ref GfeDbExecutionResultTopic

  LoadReleaseActivity:
    Type: AWS::StepFunctions::Activity
    Properties: 
      Name: !Sub "${AppName}-${Stage}-LoadReleaseActivity"

  LoadReleaseActivityArnParameter:
    Type: AWS::SSM::Parameter
    Properties:
      Type: String
      Name: !Sub '/${AppName}/${Stage}/${AWS::Region}/LoadReleaseActivityArn'
      Description: "ARN of gfe-db load release activity"
      Value: !GetAtt LoadReleaseActivity.Arn

  UpdatePipelineLogGroup:
    Type: AWS::Logs::LogGroup
    Properties:
      LogGroupName: !Sub "${Stage}-${AppName}-pipeline-execution-logs"

  UpdatePipelineStateMachineArnParameter:
    Type: AWS::SSM::Parameter
    Properties:
      Type: String
      Name: !Sub '/${AppName}/${Stage}/${AWS::Region}/UpdatePipelineStateMachineArn'
      Description: "ARN of gfe-db update pipeline state machine"
      Value: !GetAtt UpdatePipelineStateMachine.Arn

# CloudWatch Alarm for failed pipeline executions
  UpdatePipelineStateMachineExecutionAlarm:
    Type: AWS::CloudWatch::Alarm
    Properties:
      AlarmDescription: !Sub '${UpdatePipelineStateMachine} state machine errors'
      ActionsEnabled: true
      AlarmActions:
        - !Sub '{{resolve:ssm:/${AppName}/${Stage}/${AWS::Region}/DataPipelineErrorsTopicArn}}'
      MetricName: ExecutionsFailed
      Namespace: AWS/States
      Statistic: Sum
      Period: 86400
      EvaluationPeriods: 1
      Threshold: 1
      ComparisonOperator: GreaterThanOrEqualToThreshold
      Dimensions:
        - Name: StateMachineArn
          Value: !GetAtt UpdatePipelineStateMachine.Arn

# CloudWatch Alarm for failed pipeline integrations (Batch jobs)
  UpdatePipelineStateMachineIntegrationAlarm:
    Type: AWS::CloudWatch::Alarm
    Properties:
      AlarmDescription: !Sub '${UpdatePipelineStateMachine} state machine errors'
      ActionsEnabled: true
      AlarmActions:
        - !Sub '{{resolve:ssm:/${AppName}/${Stage}/${AWS::Region}/DataPipelineErrorsTopicArn}}'
      MetricName: ServiceIntegrationsFailed
      Namespace: AWS/States
      Statistic: Sum
      Period: 86400
      EvaluationPeriods: 1
      Threshold: 1
      ComparisonOperator: GreaterThanOrEqualToThreshold
      Dimensions:
        - Name: ServiceIntegrationResourceArn
          Value: !Sub 'arn:aws:states:${AWS::Region}:${AWS::AccountId}:batch:submitJob.sync'

  FailedAllelesQueue:
    Type: AWS::SQS::Queue
    Properties:
      VisibilityTimeout: 20
      RedrivePolicy:
        deadLetterTargetArn: !GetAtt FailedAllelesDeadLetterQueue.Arn
        maxReceiveCount: 5
  FailedAllelesDeadLetterQueue:
    Type: AWS::SQS::Queue

  Neo4jLoadQueryDocument: 
    Type: AWS::SSM::Document
    Properties:
      DocumentType: "Command"
      DocumentFormat: "YAML"
      TargetType: "/AWS::EC2::Instance"
      Content:
        schemaVersion: "2.2"
        description: !Sub "Load Neo4j for ${AppName}"
        parameters:
          sourceType:
            type: "String"
            description: "S3"
            default: "S3"
          sourceInfo:
            type: "StringMap"
            description: !Sub "Downloads all files under the ${AppName} scripts prefix"
            default:
              path: !Sub 'https://{{resolve:ssm:/${AppName}/${Stage}/${AWS::Region}/DataBucketName}}.s3.amazonaws.com/config/database/scripts/'
          commandLine:
            type: "String"
            description: "These commands are invoked by a Lambda script which sets the correct parameters (Refer to documentation)."
            default: !Sub 'bash start_task.sh ${AppName} ${Stage}'
          workingDirectory:
            type: "String"
            description: "Working directory"
            default: "/home/ubuntu"
          executionTimeout:
            type: "String"
            description: "(Optional) The time in seconds for a command to complete before it is considered to have failed. Default is 3600 (1 hour). Maximum is 28800 (8 hours)."
            default: "28800"
        mainSteps:
          - action: "aws:downloadContent"
            name: "downloadContent"
            inputs:
              sourceType: "{{ sourceType }}"
              sourceInfo: "{{ sourceInfo }}"
              destinationPath: "{{ workingDirectory }}"
          - action: "aws:runShellScript"
            name: "runShellScript"
            inputs: 
              runCommand:
                - ""
                - "directory=$(pwd)"
                - "export PATH=$PATH:$directory"
                - " {{ commandLine }} " 
                - ""
              workingDirectory: "{{ workingDirectory }}"
              timeoutSeconds: "{{ executionTimeout }}"

  Neo4jLoadQueryDocumentNameParameter:
    Type: AWS::SSM::Parameter
    Properties:
      Type: String
      Name: !Sub '/${AppName}/${Stage}/${AWS::Region}/Neo4jLoadQueryDocumentName'
      Description: "Name of SSM document for loading Neo4j"
      Value: !Ref Neo4jLoadQueryDocument

  # TODO verify that this works, had problem with file's content not showing up in files on db instance
  # TODO move to database layer
  DatabaseSyncScriptsDocument: 
    Type: AWS::SSM::Document
    Properties:
      DocumentType: "Command"
      DocumentFormat: "YAML"
      TargetType: "/AWS::EC2::Instance"
      Content:
        schemaVersion: "2.2"
        description: !Sub "Sync database scripts for ${AppName}"
        parameters:
          sourceType:
            type: "String"
            description: "S3"
            default: "S3"
          sourceInfo:
            type: "StringMap"
            description: !Sub "Downloads all files under the ${AppName} scripts prefix"
            default:
              path: !Sub 'https://{{resolve:ssm:/${AppName}/${Stage}/${AWS::Region}/DataBucketName}}.s3.amazonaws.com/${ConfigS3Path}/database/scripts/'
          commandLine:
            type: "String"
            description: "Deletes ETag files created by SSM Agent."
            default: 'find . -name "*.etag" -exec rm -f {} \; && find . \( -name "*.sh" -o -name "Makefile" -o -name "init" \) -exec chown bitnami {} \; && find . \( -name "*.sh" -o -name "Makefile" -o -name "init" \) -exec chgrp bitnami {} \;'
          workingDirectory:
            type: "String"
            description: "Working directory"
            default: "/home/bitnami"
          executionTimeout:
            type: "String"
            description: "(Optional) The time in seconds for a command to complete before it is considered to have failed. Default is 3600 (1 hour). Maximum is 28800 (8 hours)."
            default: "300"
        mainSteps:
          - action: "aws:downloadContent"
            name: "downloadContent"
            inputs:
              sourceType: "{{ sourceType }}"
              sourceInfo: "{{ sourceInfo }}"
              destinationPath: "{{ workingDirectory }}"
          - action: "aws:runShellScript"
            name: "runShellScript"
            inputs: 
              runCommand:
                - ""
                - "directory=$(pwd)"
                - "export PATH=$PATH:$directory"
                - " {{ commandLine }} " 
                - ""
              workingDirectory: "{{ workingDirectory }}"
              timeoutSeconds: "{{ executionTimeout }}"

  DatabaseSyncScriptsDocumentNameParameter:
    Type: AWS::SSM::Parameter
    Properties:
      Type: String
      Name: !Sub '/${AppName}/${Stage}/${AWS::Region}/DatabaseSyncScriptsDocumentName'
      Description: "Name of SSM document for syncing shell scripts to the database"
      Value: !Ref DatabaseSyncScriptsDocument

  GfedbPipelineParamMappingsParameter:
    Type: AWS::SSM::Parameter
    Properties:
      Type: String
      Name: !Sub '/${AppName}/${Stage}/${AWS::Region}/GfedbPipelineParamMappings'
      Description: !Sub 'SSM Parameter and SecretsManager parameter paths for ${AppName} pipeline layer'
      Tier: Standard
      Value: !Sub |
        {
          "ssm": [
              "/${AppName}/${Stage}/${AWS::Region}/GithubSourceRepository",
              "/${AppName}/${Stage}/${AWS::Region}/GitHubPersonalAccessToken",
              "/${AppName}/${Stage}/${AWS::Region}/ExecutionStateTableName",
              "/${AppName}/${Stage}/${AWS::Region}/BuildJobQueueArn",
              "/${AppName}/${Stage}/${AWS::Region}/BuildServiceRepositoryName",
              "/${AppName}/${Stage}/${AWS::Region}/GfeDbProcessingQueueUrl",
              "/${AppName}/${Stage}/${AWS::Region}/GfeDbExecutionResultTopicArn",
              "/${AppName}/${Stage}/${AWS::Region}/LoadReleaseActivityArn",
              "/${AppName}/${Stage}/${AWS::Region}/UpdatePipelineStateMachineArn",
              "/${AppName}/${Stage}/${AWS::Region}/Neo4jLoadQueryDocumentName",
              "/${AppName}/${Stage}/${AWS::Region}/DatabaseSyncScriptsDocumentName"
          ],
          "secretsmanager": [
              "/${AppName}/${Stage}/${AWS::Region}/GitHubPersonalAccessToken"
          ]
        }